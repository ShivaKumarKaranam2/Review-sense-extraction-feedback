{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03f884b2b7784083b779f6d61912834b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf0c0dd092ed4a37bb22831a769d2711",
              "IPY_MODEL_a7ec5185b5414ab8ad7bc0bfcc0d5155",
              "IPY_MODEL_5f8f9147bd2c4babb9228bbd800fafc7",
              "IPY_MODEL_b92c3b9a19f649808a8504bc7f7a69e3",
              "IPY_MODEL_4bdc3651620f46e5b5d78be578f795f8"
            ],
            "layout": "IPY_MODEL_d2b603a3ede54a3695518644497996da"
          }
        },
        "cf0c0dd092ed4a37bb22831a769d2711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be062724c5fc4af4901e37858373ea91",
            "placeholder": "​",
            "style": "IPY_MODEL_6534b40bf99246e7a4624ebb29f06802",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a7ec5185b5414ab8ad7bc0bfcc0d5155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_139288c9843b420aa61abe9bc70fd32a",
            "placeholder": "​",
            "style": "IPY_MODEL_f4af92a7d9ca491f8abdd3fbad359bbd",
            "value": ""
          }
        },
        "5f8f9147bd2c4babb9228bbd800fafc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_db4b13c6bfff4d53bfdd4dec560d978b",
            "style": "IPY_MODEL_a06827f9493b4f82972fbab3af345aba",
            "value": true
          }
        },
        "b92c3b9a19f649808a8504bc7f7a69e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f1ef64e9a7d04ff4a3b81ac1e51eb501",
            "style": "IPY_MODEL_c23b869e23c1486d969f2b0ca4011f6c",
            "tooltip": ""
          }
        },
        "4bdc3651620f46e5b5d78be578f795f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_974fa3c4e7bd414c8de55376f91a9ec9",
            "placeholder": "​",
            "style": "IPY_MODEL_cb2d6f9d3d9d41ad8d74852f5822e94e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d2b603a3ede54a3695518644497996da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "be062724c5fc4af4901e37858373ea91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6534b40bf99246e7a4624ebb29f06802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "139288c9843b420aa61abe9bc70fd32a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4af92a7d9ca491f8abdd3fbad359bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db4b13c6bfff4d53bfdd4dec560d978b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06827f9493b4f82972fbab3af345aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ef64e9a7d04ff4a3b81ac1e51eb501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23b869e23c1486d969f2b0ca4011f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "974fa3c4e7bd414c8de55376f91a9ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2d6f9d3d9d41ad8d74852f5822e94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers datasets evaluate peft"
      ],
      "metadata": {
        "id": "jY-ZhmJKKm0c"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F0JzRUxoJvVh"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the base model\n",
        "\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "\n",
        "#define label maps\n",
        "id2label = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"NEUTRAL\": 1, \"POSITIVE\": 2}"
      ],
      "metadata": {
        "id": "IuXNUfBFQHnV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "03f884b2b7784083b779f6d61912834b",
            "cf0c0dd092ed4a37bb22831a769d2711",
            "a7ec5185b5414ab8ad7bc0bfcc0d5155",
            "5f8f9147bd2c4babb9228bbd800fafc7",
            "b92c3b9a19f649808a8504bc7f7a69e3",
            "4bdc3651620f46e5b5d78be578f795f8",
            "d2b603a3ede54a3695518644497996da",
            "be062724c5fc4af4901e37858373ea91",
            "6534b40bf99246e7a4624ebb29f06802",
            "139288c9843b420aa61abe9bc70fd32a",
            "f4af92a7d9ca491f8abdd3fbad359bbd",
            "db4b13c6bfff4d53bfdd4dec560d978b",
            "a06827f9493b4f82972fbab3af345aba",
            "f1ef64e9a7d04ff4a3b81ac1e51eb501",
            "c23b869e23c1486d969f2b0ca4011f6c",
            "974fa3c4e7bd414c8de55376f91a9ec9",
            "cb2d6f9d3d9d41ad8d74852f5822e94e"
          ]
        },
        "id": "2FTiar_YiYZc",
        "outputId": "910d664f-1159-4f29-f8a6-6856c7a9147d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03f884b2b7784083b779f6d61912834b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate classification model from model_checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=3, id2label=id2label, label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEr0nSWxQ3W7",
        "outputId": "190e2bac-bc87-4598-8afa-4a6d092f0d28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "import pandas as pd\n",
        "\n",
        "dataset = load_dataset('csv', data_files='/content/cleaned_sentiment_data.csv')\n",
        "dataset\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1wBPdLeRNSt",
        "outputId": "0a7efb8c-fb26-4973-9f3c-8f4d131c52d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Cleaned_Sentence', 'Sentiment'],\n",
              "        num_rows: 5842\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import Dataset\n",
        "\n",
        "# dataset = [\n",
        "#     {\"text\":\"geosolutions technology leverage benefon gps solution provide location base search technology community platform location relevant multimedia content new powerful commercial model .\",\n",
        "#      \"sentiment\": \"2\"},\n",
        "#     {\"text\":\"$ esi low $ 1.50 $ 2.50 bk real possibility\",\n",
        "#      \"sentiment\": \"0\"},\n",
        "#     {\"text\":\"accord finnishrussian chamber commerce major construction company finland operate russia .\",\"sentiment\": \"1\"\n",
        "#     },\n",
        "# ]\n",
        "\n",
        "# dataset = Dataset.from_list(dataset)"
      ],
      "metadata": {
        "id": "0CTa2s2LUiKx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
        "\n",
        "\n",
        "#create tokenize function\n",
        "def tokenize_function(examples):\n",
        "  #extract text and sentiment\n",
        "  text = examples[\"Cleaned_Sentence\"]\n",
        "  sentiment = examples[\"Sentiment\"]\n",
        "\n",
        "  # tokenize and truncate text\n",
        "  tokenizer.truncate_side = \"left\"\n",
        "  tokenized_inputs = tokenizer(\n",
        "      text,\n",
        "      return_tensors=\"np\",\n",
        "      truncation = True,\n",
        "      max_length = 512\n",
        "      )\n",
        "\n",
        "  # Add labels to the tokenized inputs\n",
        "  tokenized_inputs[\"labels\"] = [int(s) for s in sentiment] # Convert sentiment to integer labels\n",
        "\n",
        "  return tokenized_inputs\n",
        "\n",
        "# add pad token if none exits\n",
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# tokenize the dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_datasets # Corrected variable name to display the result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k7unfCLVaVS",
        "outputId": "35294c78-540c-47b3-9597-954fac447ff3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Cleaned_Sentence', 'Sentiment', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 5842\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tokenized_datasets))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybwm0QC_nSZc",
        "outputId": "a96296fc-eac4-4a0a-944a-148ada811b6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.dataset_dict.DatasetDict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.2) # 80% train, 20% validation\n",
        "\n",
        "# Create a new DatasetDict with split data and remove unnecessary columns\n",
        "tokenized_datasets = DatasetDict({\n",
        "    'train': train_test_split['train'].remove_columns(['Cleaned_Sentence', 'Sentiment']),\n",
        "    'validation': train_test_split['test'].remove_columns(['Cleaned_Sentence', 'Sentiment'])\n",
        "})\n",
        "\n",
        "display(tokenized_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cBAIv_QpmJZT",
        "outputId": "1aab83e2-feb2-4660-c470-a98e67e5c3c0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DatasetDict' object has no attribute 'train_test_split'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1394783471.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split the dataset into training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_test_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 80% train, 20% validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a new DatasetDict with split data and remove unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m tokenized_datasets = DatasetDict({\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'train_test_split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "ee46be9d",
        "outputId": "4306c0ad-2449-4be7-d75a-ae536e6ef1de"
      },
      "source": [
        "display(tokenized_datasets)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Cleaned_Sentence', 'Sentiment', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 4673\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Cleaned_Sentence', 'Sentiment', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1169\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "data_collator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP92eliTXwmo",
        "outputId": "201d5f4d-9348-404b-87b1-97b3fb84d509"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "3JmW1QfEY-mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "#define an evaluation function to pass into trainer later\n",
        "\n",
        "def compute_metrics(p):\n",
        "  predictions, labels = p\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "  acc = accuracy.compute(predictions=predictions, references=labels)\n",
        "  return {\"accuracy\": accuracy.compute(predictions=predictions,\n",
        "  references = labels)}"
      ],
      "metadata": {
        "id": "0qrKeH8tYthx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Untrained model performance"
      ],
      "metadata": {
        "id": "G3pxMcIsZ8R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define list of examples\n",
        "text_list = [\n",
        "    \"The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model .\",\n",
        "    \"$ESI on lows, down $1.50 to $2.50 BK a real possibility\",\n",
        "    \"According to the Finnish-Russian Chamber of Commerce , all the major construction companies of Finland are operating in Russia .\"\n",
        "]\n",
        "\n",
        "print(\"Untrained model predictions.\")\n",
        "print(\"-----------------------------\")\n",
        "\n",
        "# Determine the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # Move model to the device\n",
        "\n",
        "for text in text_list:\n",
        "  #tokenize text\n",
        "  inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device) # Move input tensor to the device\n",
        "\n",
        "  #compute logits\n",
        "  logits = model(inputs).logits\n",
        "\n",
        "  #convert logits to label\n",
        "  predictions = torch.argmax(logits)\n",
        "\n",
        "  print(text + \" - \"+ id2label[predictions.tolist()])\n",
        "  print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W98psLVSZhs9",
        "outputId": "ed97c15c-e042-4a84-b1d7-907a90b6b230"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained model predictions.\n",
            "-----------------------------\n",
            "The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model . - NEUTRAL\n",
            "tensor([[  101,  1996, 20248, 19454, 13700,  2015,  2974,  2097, 21155,  3841,\n",
            "         12879,  2239,  1005,  1055, 14658,  7300,  2011,  4346,  3295,  2241,\n",
            "          3945,  2974,  1010,  1037,  4279,  4132,  1010,  3295,  7882, 14959,\n",
            "          4180,  1998,  1037,  2047,  1998,  3928,  3293,  2944,  1012,   102]],\n",
            "       device='cuda:0')\n",
            "$ESI on lows, down $1.50 to $2.50 BK a real possibility - NEUTRAL\n",
            "tensor([[  101,  1002,  9686,  2072,  2006,  2659,  2015,  1010,  2091,  1002,\n",
            "          1015,  1012,  2753,  2000,  1002,  1016,  1012,  2753, 23923,  1037,\n",
            "          2613,  6061,   102]], device='cuda:0')\n",
            "According to the Finnish-Russian Chamber of Commerce , all the major construction companies of Finland are operating in Russia . - NEUTRAL\n",
            "tensor([[ 101, 2429, 2000, 1996, 6983, 1011, 2845, 4574, 1997, 6236, 1010, 2035,\n",
            "         1996, 2350, 2810, 3316, 1997, 6435, 2024, 4082, 1999, 3607, 1012,  102]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning with LORA\n"
      ],
      "metadata": {
        "id": "CkYwzQwgbZpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(task_type=\"SEQ_CLS\", #Sequence calssificaion\n",
        "                         r=4,  #intrinsic rank of trainable weight matrix\n",
        "                         lora_alpha = 32, # this is like a learning rate\n",
        "                         lora_dropout=0.01, #probablity of the dropout\n",
        "                         target_modules = ['q_lin'] #we apply lora to query layer\n",
        "                         )"
      ],
      "metadata": {
        "id": "S--R06-xa8Cs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLt1dCbIcCb1",
        "outputId": "fb744922-da4a-4f48-be01-143337720eba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 629,763 || all params: 67,585,542 || trainable%: 0.9318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3 # size of optimization step\n",
        "batch_size = 4 # number of examples processed per optimization step\n",
        "num_epochs = 10\n",
        "\n",
        "#defining training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"sentiment_model\",\n",
        "    learning_rate = lr,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    num_train_epochs = num_epochs,\n",
        "    weight_decay = 0.01,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    load_best_model_at_end = True,\n",
        ")"
      ],
      "metadata": {
        "id": "pV1t_eT0cVWx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.45.2 peft==0.17.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBVhkBnriCnb",
        "outputId": "fc7124c7-9039-4a34-f162-3146b57eb40e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.45.2 in /usr/local/lib/python3.12/dist-packages (4.45.2)\n",
            "Requirement already satisfied: peft==0.17.1 in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (0.6.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.17.1) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.17.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.17.1) (1.11.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.17.1) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.2) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.17.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.17.1) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creater trainer object\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model, # our peft model\n",
        "    args = training_args, # hyperparameter\n",
        "    train_dataset = tokenized_datasets['train'], # Use the training split\n",
        "    eval_dataset = tokenized_datasets['validation'], # Use the validation split\n",
        "    tokenizer = tokenizer, #define tokenizer\n",
        "    data_collator = data_collator, # this will dynamically pad examples\n",
        "    compute_metrics = compute_metrics, # evaluates model using compute_metrics\n",
        ")\n",
        "\n",
        "#train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "FrhCGVZ0e6hj",
        "outputId": "2458b5d4-c99f-444e-d5cc-206bf8f4685f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11690' max='11690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11690/11690 04:50, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.619100</td>\n",
              "      <td>0.730628</td>\n",
              "      <td>{'accuracy': 0.7476475620188195}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.594800</td>\n",
              "      <td>0.746123</td>\n",
              "      <td>{'accuracy': 0.7279726261762189}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.654100</td>\n",
              "      <td>0.805193</td>\n",
              "      <td>{'accuracy': 0.7553464499572284}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.590400</td>\n",
              "      <td>0.759899</td>\n",
              "      <td>{'accuracy': 0.7279726261762189}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.590100</td>\n",
              "      <td>0.782700</td>\n",
              "      <td>{'accuracy': 0.7331052181351583}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.533500</td>\n",
              "      <td>0.802292</td>\n",
              "      <td>{'accuracy': 0.7433704020530368}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.472500</td>\n",
              "      <td>0.908017</td>\n",
              "      <td>{'accuracy': 0.7467921300256629}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.456100</td>\n",
              "      <td>0.888691</td>\n",
              "      <td>{'accuracy': 0.7459366980325064}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.451200</td>\n",
              "      <td>0.979279</td>\n",
              "      <td>{'accuracy': 0.739093242087254}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.402900</td>\n",
              "      <td>0.970635</td>\n",
              "      <td>{'accuracy': 0.737382378100941}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.7476475620188195}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7279726261762189}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7553464499572284}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7279726261762189}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7331052181351583}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7433704020530368}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7467921300256629}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.7459366980325064}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.739093242087254}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.737382378100941}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11690, training_loss=0.5326281290568278, metrics={'train_runtime': 290.5429, 'train_samples_per_second': 160.837, 'train_steps_per_second': 40.235, 'total_flos': 376972821223200.0, 'train_loss': 0.5326281290568278, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trained model performance"
      ],
      "metadata": {
        "id": "88FkJokWjC5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # moving model to the device\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "\n",
        "print(\"---------------------------\")\n",
        "\n",
        "for text in text_list:\n",
        "  inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device) # Move input tensor to the device\n",
        "\n",
        "  logits = model(inputs).logits\n",
        "\n",
        "  predictions = torch.argmax(logits)\n",
        "\n",
        "  print(text + \" - \" + id2label[predictions.tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NRNwNMWkcFY",
        "outputId": "f2426168-6ad3-4493-f548-3103a1be01f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model predictions:\n",
            "---------------------------\n",
            "The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model . - POSITIVE\n",
            "$ESI on lows, down $1.50 to $2.50 BK a real possibility - NEGATIVE\n",
            "According to the Finnish-Russian Chamber of Commerce , all the major construction companies of Finland are operating in Russia . - NEUTRAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a directory to save the model\n",
        "save_directory = \"./fine_tuned_sentiment_model\"\n",
        "\n",
        "# Save the PEFT model (LoRA adapter weights)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Fine-tuned model and tokenizer saved to {save_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A81CHi44lFaM",
        "outputId": "f9c10452-ff29-44c1-cd70-8491bc89a6bf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model and tokenizer saved to ./fine_tuned_sentiment_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the directory where the model was saved\n",
        "save_directory = \"./fine_tuned_sentiment_model\"\n",
        "\n",
        "# List files in the directory\n",
        "for filename in os.listdir(save_directory):\n",
        "    filepath = os.path.join(save_directory, filename)\n",
        "    # Check if it's a file before attempting to download\n",
        "    if os.path.isfile(filepath):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        files.download(filepath)\n",
        "\n",
        "print(\"Download process initiated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "SX3SAhb7wXkq",
        "outputId": "14a837ea-8922-4092-cf6e-5e3e011bf4d4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading adapter_config.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a1fcbaf-93ba-49e9-b582-0ee04aa142d0\", \"adapter_config.json\", 871)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading adapter_model.safetensors...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a8d0788-d299-48da-a7c8-873a8fd11878\", \"adapter_model.safetensors\", 2521180)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vocab.txt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7b3c273c-6046-4207-889c-a01cf3f1b01f\", \"vocab.txt\", 231508)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading special_tokens_map.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_00f30ec6-5198-4df7-9f08-3f43dd18c1e6\", \"special_tokens_map.json\", 125)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tokenizer.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8ef2f8e-41ca-45de-800e-05833f00714b\", \"tokenizer.json\", 711396)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading README.md...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3db70415-20c2-4266-b052-cc219855baad\", \"README.md\", 5170)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tokenizer_config.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_73a0d7ae-dc8e-483a-926c-25f8190e0089\", \"tokenizer_config.json\", 1225)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download process initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cb05dc3",
        "outputId": "c6b692ef-b69b-4406-a559-114f730e0605"
      },
      "source": [
        "# Example text for prediction\n",
        "text_to_predict = \"This is a great day!\"\n",
        "\n",
        "# Tokenize the input text using the loaded tokenizer\n",
        "inputs = loaded_tokenizer(text_to_predict, return_tensors=\"pt\")\n",
        "\n",
        "# Move the input tensors to the same device as the loaded model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)\n",
        "inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
        "\n",
        "# Get the model's predictions (logits)\n",
        "with torch.no_grad(): # Disable gradient calculation for inference\n",
        "    outputs = loaded_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "# Map the predicted class index to the sentiment label\n",
        "predicted_label = id2label[predicted_class_id]\n",
        "\n",
        "print(f\"The sentiment of the text '{text_to_predict}' is: {predicted_label}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the text 'This is a great day!' is: POSITIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fb109a4",
        "outputId": "01a4bf1e-79bb-488b-efa7-13a6e11024d0"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import PeftModel, PeftConfig\n",
        "import torch\n",
        "\n",
        "# Define the directory where you saved the model\n",
        "save_directory = \"./fine_tuned_sentiment_model\"\n",
        "\n",
        "# Load the base model\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)\n",
        "\n",
        "# Load the PEFT model (LoRA adapter weights)\n",
        "# We load the base model first and then add the PEFT layers\n",
        "loaded_model = PeftModel.from_pretrained(base_model, save_directory)\n",
        "\n",
        "# You can also load the tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "print(\"Fine-tuned model and tokenizer loaded successfully.\")\n",
        "\n",
        "# You can now use loaded_model and loaded_tokenizer for inference"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    }
  ]
}